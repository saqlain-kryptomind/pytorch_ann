import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import pandas as pd
import numpy as np

# Load Titanic dataset
url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'
data = pd.read_csv(url)

print(data)

# Data Preprocessing
data = data.drop(['Name', 'Ticket', 'Cabin', 'Embarked'], axis=1)

data['Age'].fillna(data['Age'].median(), inplace=True)

data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})

data.dropna(inplace=True)

X = data.drop('Survived', axis=1).values
y = data['Survived'].values

scaler = StandardScaler()
X = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

X_train = torch.tensor(X_train, dtype=torch.float32)
y_train = torch.tensor(y_train, dtype=torch.long)
X_test = torch.tensor(X_test, dtype=torch.float32)
y_test = torch.tensor(y_test, dtype=torch.long)

# Step 3: Define the ANN Model
class TitanicANN(nn.Module):
    def __init__(self, input_dim):
        super(TitanicANN, self).__init__()
        self.layer1 = nn.Linear(input_dim, 64)
        self.layer2 = nn.Linear(64, 32)
        self.layer3 = nn.Linear(32, 16)
        self.output = nn.Linear(16, 2)

        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.relu(self.layer1(x))
        x = self.relu(self.layer2(x))
        x = self.relu(self.layer3(x))
        x = self.output(x)
        return x

input_dim = X_train.shape[1]
model = TitanicANN(input_dim)

# Step 4: Activation Function, Loss Function, and Optimizer

criterion = nn.CrossEntropyLoss()

optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)

# Step 5: Train the Model
epochs = 100
batch_size = 32

for epoch in range(epochs):
    model.train()
    for i in range(0, len(X_train), batch_size):
        # Get batch
        X_batch = X_train[i:i+batch_size]
        y_batch = y_train[i:i+batch_size]

        # Zero the gradients
        optimizer.zero_grad()

        # Forward pass
        outputs = model(X_batch)
        
        # Compute the loss
        loss = criterion(outputs, y_batch)

        # Backward pass and optimize
        loss.backward()
        optimizer.step()

    if epoch % 10 == 0:
        print(f'Epoch [{epoch}/{epochs}], Loss: {loss.item():.4f}')

# Step 6: Evaluate the Model on the Test Set
model.eval()
with torch.no_grad():
    y_pred = model(X_test)
    _, predicted = torch.max(y_pred, 1)

    accuracy = (predicted == y_test).sum().item() / y_test.size(0)
    print(f'Accuracy on test data: {accuracy * 100:.2f}%')

import gradio as gr

def predict_titanic(Pclass, Sex, Age, SibSp, Parch, Fare):
    try:
        passenger_id_placeholder = 0  

        input_data = np.array([passenger_id_placeholder, Pclass, 1 if Sex.lower() == 'female' else 0, Age, SibSp, Parch, Fare]).reshape(1, -1)

        input_data = scaler.transform(input_data)

        input_tensor = torch.tensor(input_data, dtype=torch.float32)

        # Make prediction
        model.eval()
        with torch.no_grad():
            output = model(input_tensor)
            _, predicted = torch.max(output, 1)

        return "Survived" if predicted.item() == 1 else "Did not survive"
    except Exception as e:
        return f"Error: {str(e)}"




# Gradio interface
interface = gr.Interface(
    fn=predict_titanic,
    inputs=[
        gr.Dropdown(choices=[1, 2, 3], label="Passenger Class (Pclass)"),
        gr.Radio(choices=["male", "female"], label="Sex"),
        gr.Slider(0, 80, step=1, label="Age"),
        gr.Slider(0, 10, step=1, label="Number of Siblings/Spouses (SibSp)"),
        gr.Slider(0, 10, step=1, label="Number of Parents/Children (Parch)"),
        gr.Slider(0, 100, step=1, label="Fare"),
    ],
    outputs=gr.Textbox(label="Prediction"),
    title="Titanic Survival Prediction",
    description="Enter passenger details to predict survival chances on the Titanic."
)

# Launch Gradio app inline
interface.launch(share=True, inline=True)
